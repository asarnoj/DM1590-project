{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e3a12c",
   "metadata": {},
   "source": [
    "# Heart Disease Classifier â€“ Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7eec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a01d0",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Cleaning\n",
    "\n",
    "Our dataset (https://archive.ics.uci.edu/dataset/45/heart+disease) have 14 features, two of which (ca and thal) have missing values. We checked the dataset and found that 6 rows contain missing values. From here we have two main options to make the dataset usable.\n",
    "\n",
    "1. **Exclude the 6 incomplete rows:** This is simple and safe. The dataset contains 303 rows, so removing 6 will reduce the size to roughly 98% which most likely wont affect the performance a lot. However, this solution assumes that the missing data have no correlation to the other values.\n",
    "2. **Fill the missing data using the mean or mode:** For numerical features (like ca), the mean can be used. And for categorical features (like thal), the mode can be used\n",
    "3. **Predict the missing values:** We could also try to predict the values using regression or KNN\n",
    "\n",
    "**Our choice:** We choose the first option since it keeps the cleaning process simple and avoids inacurrate assumptions that could affect our results.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "num         0\n",
      "dtype: int64\n",
      "Original size: 303 rows\n",
      "After dropping missing: 297 rows\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"./heart+disease/processed.cleveland.data\", header=None, na_values=\"?\")\n",
    "\n",
    "# Add column names (from the 14 features)\n",
    "df.columns = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
    "    \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"\n",
    "]\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Drop all the rows that are incomplete\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"Original size: {len(df)} rows\")\n",
    "print(f\"After dropping missing: {len(df_clean)} rows\")\n",
    "# 6 rows dropped. Seems to check out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b8d01",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "First, we'll take a look at all the features to see what are numerical and what are categorical. The infromation for the data set says that all of the values are transfered to numerical which is good! And when printing the data, we can confirm that it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15424c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca  thal  num  \n",
      "0    3.0  0.0   6.0    0  \n",
      "1    2.0  3.0   3.0    2  \n",
      "2    2.0  2.0   7.0    1  \n",
      "3    3.0  0.0   3.0    0  \n",
      "4    1.0  0.0   3.0    0  \n",
      "age         float64\n",
      "sex         float64\n",
      "cp          float64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg     float64\n",
      "thalach     float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope       float64\n",
      "ca          float64\n",
      "thal        float64\n",
      "num           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preview the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check data types\n",
    "print(df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25734ed4",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Learning: PCA + GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d306c",
   "metadata": {},
   "source": [
    "## 4. Supervised Learning: SVM, Random Forest, KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7faf468",
   "metadata": {},
   "source": [
    "## 5. Feature Selection & Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73edf7df",
   "metadata": {},
   "source": [
    "## 6. Evaluation: Accuracy, F1, Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f1fd4",
   "metadata": {},
   "source": [
    "## 7. Conclusions & Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
