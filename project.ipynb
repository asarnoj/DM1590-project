{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e3a12c",
   "metadata": {},
   "source": [
    "# Heart Disease Classifier â€“ Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7eec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a01d0",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Cleaning\n",
    "\n",
    "Our dataset have 14 features, two of which (ca and thal) have missing values. We checked the dataset and found that 6 rows contain missing values. From here we have two main options to make the dataset usable.\n",
    "\n",
    "1. **Exclude the 6 incomplete rows:** This is simple and safe. The dataset contains 303 rows, so removing 6 will reduce the size to roughly 98% which most likely wont affect the performance a lot. However, this solution assumes that the missing data have no correlation to the other values.\n",
    "2. **Fill the missing data using the mean or mode:** For numerical features (like ca), the mean can be used. And for categorical features (like thal), the mode can be used\n",
    "3. **Predict the missing values:** We could also try to predict the values using regression or KNN\n",
    "\n",
    "**Our choice:** We choose the first option since it keeps the cleaning process simple and avoids inacurrate assumptions that could affect our results.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed07dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "num         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"./heart+disease/processed.cleveland.data\", header=None, na_values=\"?\")\n",
    "\n",
    "# Add column names (from the 14 features)\n",
    "df.columns = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
    "    \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"\n",
    "]\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b8d01",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25734ed4",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Learning: PCA + GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d306c",
   "metadata": {},
   "source": [
    "## 4. Supervised Learning: SVM, Random Forest, KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7faf468",
   "metadata": {},
   "source": [
    "## 5. Feature Selection & Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73edf7df",
   "metadata": {},
   "source": [
    "## 6. Evaluation: Accuracy, F1, Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f1fd4",
   "metadata": {},
   "source": [
    "## 7. Conclusions & Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
